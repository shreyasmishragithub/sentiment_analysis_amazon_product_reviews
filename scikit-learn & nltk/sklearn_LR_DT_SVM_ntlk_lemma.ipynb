{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_LR_DT_SVM_ntlk_lemma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvz-o_rtWSAD",
        "colab_type": "code",
        "outputId": "30ac4450-18af-4e42-c462-7d05b311aa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MnRKfgBVwnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK5DX5hfV7MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-piwfbpXV9CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data= pd.read_csv(r'/content/drive/My Drive/amazon_books_review.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltl-Huc6Watw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cleaned = data.head(100000)\n",
        "df_cleaned['star_rating'].count()\n",
        "df_cleaned['star_rating'].unique()\n",
        "df_cleaned['star_rating'].value_counts()\n",
        "indexNames = df_cleaned[ df_cleaned['star_rating'] == 'star_rating' ].index\n",
        "df_cleaned.drop(indexNames,inplace=True)\n",
        "df_cleaned.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1N2-J42W1ox",
        "colab_type": "code",
        "outputId": "be1f77d0-25f0-4c4e-add5-4ff8a13ed69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "df_cleaned['star_rating']=df_cleaned['star_rating'].astype(float).astype(int)\n",
        "df_cleaned['review_body']=df_cleaned['review_body'].str.replace('<br />', r'')\n",
        "df_cleaned['review_body']=df_cleaned['review_body'].str.replace(\"[,'!;.–`:?><-]\",'')\n",
        "#df_cleaned['review_body']=df_cleaned['review_body'].str.replace(\"[!#$%&'()*+, -./:;<=>?@[\\]^_`{|}~]\",'')\n",
        "df_cleaned['review_body']=df_cleaned['review_body'].str.lower()\n",
        "#df_cleaned=df_cleaned[df_cleaned.review_body.str.split(' ').str.len()<300]\n",
        "df_cleaned['review_body']=df_cleaned.review_body.str.replace('[^a-zA-Z ]', '')\n",
        "df_cleaned.dropna(inplace=True)\n",
        "df_cleaned.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "star_rating        0\n",
              "review_headline    0\n",
              "review_body        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjh_FqvULmmx",
        "colab_type": "code",
        "outputId": "a91fce2d-f466-4657-a633-d268336fa87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "def get_lemmatized_text(corpus):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    for i in range(0,len(corpus)):\n",
        "       corpus.iloc[i] =' '.join([lemmatizer.lemmatize(word) for word in corpus.iloc[i].split()])\n",
        "get_lemmatized_text(df_cleaned['review_body'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5l7zxToXXLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def partition(x):\n",
        "    if x<3:\n",
        "        return 'Negative'\n",
        "    elif x>3:\n",
        "        return 'Positive'\n",
        "    return 'Neutral'\n",
        "\n",
        "actualScore = df_cleaned['star_rating']\n",
        "positiveNegative = actualScore.map(partition)\n",
        "df_cleaned['star_rating'] = positiveNegative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdQby0ZIXcCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=df_cleaned['review_body']\n",
        "y_train=df_cleaned['star_rating']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hoc0YQoZBj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test= pd.read_csv(r'/content/drive/My Drive/test.csv')\n",
        "df_cleaned = data_test\n",
        "indexNames = df_cleaned[ df_cleaned['ratings'] == 'ratings' ].index\n",
        "df_cleaned.drop(indexNames,inplace=True)\n",
        "df_cleaned.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmS7gvrfZyQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cleaned['review_body']=df_cleaned['review_body'].str.replace('<br />', r'')\n",
        "df_cleaned['review_body']=df_cleaned['review_body'].str.replace(\"[,'!;.–`:?><-]\",'')\n",
        "#df_cleaned['review_body']=df_cleaned['review_body'].str.replace(\"[!#$%&'()*+, -./:;<=>?@[\\]^_`{|}~]\",'')\n",
        "df_cleaned['review_body']=df_cleaned['review_body'].str.lower()\n",
        "#df_cleaned=df_cleaned[df_cleaned.review_body.str.split(' ').str.len()<300]\n",
        "df_cleaned['review_body']=df_cleaned.review_body.str.replace('[^a-zA-Z ]', '')\n",
        "df_cleaned.dropna(inplace=True)\n",
        "df_cleaned.isna().sum()\n",
        "get_lemmatized_text(df_cleaned['review_body'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAbYeZVHNKFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=df_cleaned['review_body']\n",
        "y_test=df_cleaned['ratings']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEqKSe2Nayhs",
        "colab_type": "code",
        "outputId": "b690423f-b7e8-4386-efeb-e551d7872d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('vect', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
        "    ('clf', LogisticRegression(max_iter=500,C=0.1,random_state=40,solver='newton-cg')),\n",
        "])\n",
        "clf = clf.fit(X_train, y_train)\n",
        "accuracy_train=accuracy_score(y_train, clf.predict(X_train))\n",
        "accuracy_test=accuracy_score(y_test, clf.predict(X_test))\n",
        "print('Accuracy on train %f' %accuracy_train)\n",
        "print('Accuracy on test %f' %accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train 0.990350\n",
            "Accuracy on test 0.863009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgZ96YD2eGQ8",
        "colab_type": "code",
        "outputId": "e7723067-13cd-472b-f05a-43fe0655b554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = Pipeline([\n",
        "    ('vect', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
        "    ('clf', DecisionTreeClassifier()),\n",
        "])\n",
        "clf = clf.fit(X_train, y_train)\n",
        "accuracy_train=accuracy_score(y_train, clf.predict(X_train))\n",
        "accuracy_test=accuracy_score(y_test, clf.predict(X_test))\n",
        "print('Accuracy on train %f' %accuracy_train)\n",
        "print('Accuracy on test %f' %accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train 0.999920\n",
            "Accuracy on test 0.761678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj7QgI2C0xXC",
        "colab_type": "code",
        "outputId": "cf50cfa6-4398-4c74-d41d-43f7b3bc579b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = Pipeline([\n",
        "    ('vect',TfidfVectorizer()),\n",
        "    ('clf',LinearSVC()),\n",
        "])\n",
        "clf = clf.fit(X_train, y_train)\n",
        "accuracy_train=accuracy_score(y_train, clf.predict(X_train))\n",
        "accuracy_test=accuracy_score(y_test, clf.predict(X_test))\n",
        "print('Accuracy on train %f' %accuracy_train)\n",
        "print('Accuracy on test %f' %accuracy_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train 0.950267\n",
            "Accuracy on test 0.850539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWVaqS3k1Z64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}